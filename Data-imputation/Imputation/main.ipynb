{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as mlt\n",
    "import seaborn as sp\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum', 'Seasonal', 'Trend', 'Residual']\n",
    "columns = ['Day of week', 'Energy', 'stations', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour']\n",
    "# columns_extended = columns + ['Seasonal', 'Trend', 'Residual']\n",
    "columns_extended = ['Day of week', 'Energy', 'stations', 'Week Day', 'Month', 'Day of month', 'Hour', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Pre_process/Data_preprocess.ipynb\n",
    "%run ../Pre_process/Data_postprocess.ipynb\n",
    "%run Model/ResiDualNet.ipynb\n",
    "%run Model/ConvGan.ipynb\n",
    "%run Model/AutoEncoder.ipynb\n",
    "%run Model/Mean_imputation.ipynb\n",
    "%run Model/KNN_imputer.ipynb\n",
    "%run train.ipynb\n",
    "%run wrapper.ipynb\n",
    "%run helper.ipynb\n",
    "%run ../visualize.ipynb\n",
    "%run test.ipynb\n",
    "%run ../validation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_process_dataset(\"Data/Raw/boulder_2021.csv\", 'boulder')\n",
    "# pre_process_dataset(\"../Data/Raw/acn.csv\", 'acn2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/config_data.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_acn = data.acn\n",
    "    parameters_boulder = data.boulder\n",
    "    parameters_paloalto = data.paloalto\n",
    "    parameters_sap = data.sap\n",
    "    parameters_perth = data.perth\n",
    "    parameters_dundee = data.dundee\n",
    "    parameters_caltech = data.caltech\n",
    "    parameters_jpl = data.jpl\n",
    "    parameters_office = data.office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/config_model.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_seq2seq = data.impute_40.seq2seq\n",
    "    parameters_seq2seq.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_model = parameters_seq2seq\n",
    "parameter_data = parameters_caltech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'caltech2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Processed/\" + dataset + \"_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "# df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df = df[[col for col in df.columns if col != 'Year'] + ['Year']]\n",
    "df = df.copy().loc[(df['Start'] >= \"2018-10-01 00:00:00\") & (df['Start'] <= \"2020-02-29 23:00:00\")].reset_index(drop=True)\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "# df.set_index('Start', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.copy().loc[(df['Start'] >= parameter_data.train.start) & (df['Start'] <= parameter_data.train.end)].reset_index(drop=True)\n",
    "df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy().loc[(df['Start'] >= parameter_data.test.start) & (df['Start'] <= parameter_data.test.end)].reset_index(drop=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "ratio = round(missing_ratio * len(df_train))\n",
    "random_row_indices_train = np.random.choice(df_train.index, size=ratio, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "ratio = round(missing_ratio * len(df_test))\n",
    "random_row_indices_test = np.random.choice(df_test.index, size=ratio, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_missing = random_index_noise(df_train.copy(), random_row_indices_train)\n",
    "df_train_mask = np.isnan(df_train_missing)\n",
    "df_train_missing = df_train_missing.replace(np.nan, 0)\n",
    "\n",
    "df_test_missing = random_index_noise(df_test.copy(), random_row_indices_test)\n",
    "df_test_mask = np.isnan(df_test_missing)\n",
    "df_test_missing = df_test_missing.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.set_index('Start', inplace=True)\n",
    "df_train_missing.set_index('Start', inplace=True)\n",
    "df_test.set_index('Start', inplace=True)\n",
    "df_test_missing.set_index('Start', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_missing['mean'] = df_train_missing['Energy'].expanding().mean()\n",
    "# df_train_missing['std'] = df_train_missing['Energy'].expanding().std().fillna(0)\n",
    "df_train_missing = get_data_decomposition(df_train_missing)\n",
    "\n",
    "# df_test_missing['mean'] = df_test_missing['Energy'].expanding().mean()\n",
    "# df_test_missing['std'] = df_test_missing['Energy'].expanding().std().fillna(0)\n",
    "df_test_missing = get_data_decomposition(df_test_missing)\n",
    "\n",
    "# df_train['mean'] = df_train['Energy'].expanding().mean()\n",
    "# df_train['std'] = df_train['Energy'].expanding().std().fillna(0)\n",
    "df_train = get_data_decomposition(df_train)\n",
    "\n",
    "# df_test['mean'] = df_test['Energy'].expanding().mean()\n",
    "# df_test['std'] = df_test['Energy'].expanding().std().fillna(0)\n",
    "df_test = get_data_decomposition(df_test)\n",
    "\n",
    "# df_train_mask[['mean']] = df_train_missing[['mean']].isnull()\n",
    "# df_test_mask[['mean']] = df_test_missing[['mean']].isnull()\n",
    "\n",
    "df_train_mask[['Residual', 'Trend', 'Seasonal']] = df_train_missing[['Residual', 'Trend', 'Seasonal']].isnull()\n",
    "df_test_mask[['Residual', 'Trend', 'Seasonal']] = df_test_missing[['Residual', 'Trend', 'Seasonal']].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_train_missing.reset_index(drop=True, inplace=True)\n",
    "df_test_missing.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_train_mask.drop(columns=['Start'], inplace=True)\n",
    "df_test_mask.drop(columns=['Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[columns_extended]\n",
    "df_test = df_test[columns_extended]\n",
    "df_train_missing = df_train_missing[columns_extended]\n",
    "df_test_missing = df_test_missing[columns_extended]\n",
    "df_train_mask = df_train_mask[columns_extended]\n",
    "df_test_mask = df_test_mask[columns_extended]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_column = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4185,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train_real = MinMaxScaler(feature_range=(0,1))\n",
    "df_train = scaler_train_real.fit_transform(df_train)\n",
    "df_train = pd.DataFrame(df_train, columns=columns_extended)\n",
    "df_test = scaler_train_real.transform(df_test)\n",
    "df_test = pd.DataFrame(df_test, columns=columns_extended)\n",
    "\n",
    "scaler_train_missing = MinMaxScaler(feature_range=(0,1))\n",
    "df_train_missing = scaler_train_missing.fit_transform(df_train_missing)\n",
    "df_train_missing = pd.DataFrame(df_train_missing, columns=columns_extended)\n",
    "df_test_missing = scaler_train_missing.transform(df_test_missing)\n",
    "df_test_missing = pd.DataFrame(df_test_missing, columns=columns_extended)\n",
    "# df = pd.concat([first_column, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_train, real_train, mask_train = get_train_test_dataset_imputation(df_train, df_train_missing, df_train_mask, 0, parameter_model.lag_size, random_row_indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_test, real_test, mask_test = get_train_test_dataset_imputation(df_test, df_test_missing, df_test_mask, 0, parameter_model.lag_size, random_row_indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(missing_train) // batch_size\n",
    "\n",
    "# Converting to tensor\n",
    "real_train = torch.from_numpy(real_train).float().to(device)\n",
    "missing_train = torch.from_numpy(missing_train).float().to(device)\n",
    "mask_train = torch.from_numpy(mask_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelTrain(parameter_model)\n",
    "helper = ModelHelper(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(parameter_model).to(device)\n",
    "generator = Generator(parameter_model).to(device)\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr = parameter_model.learning_rate, weight_decay=0.05)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr = parameter_model.learning_rate, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_MSE = nn.MSELoss()\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset, gen_dataset, mask_data, errors_generator, errors_discriminator = wrapper.train_Gan(generator, discriminator, optimizer_discriminator, optimizer_generator, loss_function, loss_function_MSE, real_train, missing_train, mask_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_discriminator, label='d_loss')\n",
    "mlt.plot(errors_generator, label='g_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset.detach().cpu().numpy(), gen_dataset.detach().cpu().numpy(), 00, 300, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_dataset_train_seq2seq = pd.DataFrame(real_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "# real_dataset_train_seq2seq = scaler_train_real.inverse_transform(real_dataset_train_seq2seq)\n",
    "# real_dataset_train_seq2seq = torch.tensor(real_dataset_train_seq2seq)\n",
    "# #real_dataset_train_seq2seq = pd.DataFrame(real_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_dataset_train_seq2seq = pd.DataFrame(gen_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "# gen_dataset_train_seq2seq = scaler_train_real.inverse_transform(gen_dataset_train_seq2seq)\n",
    "# gen_dataset_train_seq2seq = torch.tensor(gen_dataset_train_seq2seq)\n",
    "# #gen_dataset_train_seq2seq = pd.DataFrame(gen_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing.........................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4111,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = real_test[: -(real_test.shape[0] % parameter_model.batch_size)]\n",
    "missing_test = missing_test[: -(missing_test.shape[0] % parameter_model.batch_size)]\n",
    "mask_test = mask_test[: -(mask_test.shape[0] % parameter_model.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4112,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(missing_test) // parameter_model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4113,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = torch.from_numpy(real_test).float().to(device)\n",
    "missing_test = torch.from_numpy(missing_test).float().to(device)\n",
    "mask_test = torch.from_numpy(mask_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4115,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_gan, imputed_gan, loss, mask_test_result = wrapper_test.test_gan(generator, real_test, missing_test, mask_test, loss_function_MSE, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4116,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_gan = torch.cat((imputed_gan, real_dataset_test_gan[:, -1].unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4117,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_final_gan = ((1 - mask_test_result) * real_dataset_test_gan) + (mask_test_result * imputed_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_final_gan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset + '_9-19'\n",
    "save_imputed_data(real_dataset_test_gan, imputed_dataset_final_gan, \"../Data/Imputed/50_percent/Gan/\" + dataset_name + \".csv\", columns_extended, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_dataset_test_seq2seq = pd.DataFrame(real_dataset_test_seq2seq.detach().cpu().numpy(), columns=columns_extended)\n",
    "# real_dataset_test_seq2seq = scaler_train_real.inverse_transform(real_dataset_test_seq2seq)\n",
    "real_dataset_test_gan = torch.tensor(real_dataset_test_gan.detach().cpu().numpy())\n",
    "#real_dataset_test_seq2seq = pd.DataFrame(real_dataset_test_seq2seq.detach().cpu().numpy(), columns=columns)\n",
    "# imputed_dataset = pd.DataFrame(imputed_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "# imputed_dataset = scaler_train_real.inverse_transform(imputed_dataset)\n",
    "imputed_gan = torch.tensor(imputed_gan.detach().cpu().numpy())\n",
    "#imputed_dataset = pd.DataFrame(imputed_dataset.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3739,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_test_gan.detach().cpu().numpy(), imputed_gan.detach().cpu().numpy(), 00, 300, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3665,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_dataset_test_gan[indices, 1], imputed_gan[indices, 1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_statistic, p_value = ks_2samp(real_dataset_test_gan[:, 1], imputed_gan[:, 1])\n",
    "\n",
    "# Print the results\n",
    "print(\"KS Statistic:\", ks_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResiDualNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainning------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResiDualNet(parameter_model).to(device)\n",
    "#model = Seq2SeqAttention(input_size, hidden_size, input_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameter_model.learning_rate, weight_decay = 0.005)\n",
    "loss_function_seq2seq = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4190,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelTrain(parameter_model)\n",
    "helper = ModelHelper(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset, gen_dataset, errors_generator, mask_data = wrapper.train_Seq2Seq(model, optimizer, loss_function_seq2seq, real_train, missing_train, mask_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_generator, label='d_loss')\n",
    "mlt.legend()\n",
    "\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imputation_results_two(real_dataset.detach().cpu().numpy(), gen_dataset.detach().cpu().numpy(), mask_data.detach().cpu().numpy(), 300, 450, 'Results/test_9-19.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset.detach().cpu().numpy(), gen_dataset.detach().cpu().numpy(), 2500, 3000, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4195,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_train_seq2seq = pd.DataFrame(real_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "real_dataset_train_seq2seq = scaler_train_real.inverse_transform(real_dataset_train_seq2seq)\n",
    "real_dataset_train_seq2seq = torch.tensor(real_dataset_train_seq2seq)\n",
    "#real_dataset_train_seq2seq = pd.DataFrame(real_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4196,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset_train_seq2seq = pd.DataFrame(gen_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "gen_dataset_train_seq2seq = scaler_train_real.inverse_transform(gen_dataset_train_seq2seq)\n",
    "gen_dataset_train_seq2seq = torch.tensor(gen_dataset_train_seq2seq)\n",
    "#gen_dataset_train_seq2seq = pd.DataFrame(gen_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4197,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = real_test[: -(real_test.shape[0] % parameter_model.batch_size)]\n",
    "missing_test = missing_test[: -(missing_test.shape[0] % parameter_model.batch_size)]\n",
    "mask_test = mask_test[: -(mask_test.shape[0] % parameter_model.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4198,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(missing_test) // parameter_model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = df['Energy']\n",
    "# mlt.figure(figsize=(20, 6))\n",
    "# mlt.suptitle('Gan prediction on test dataset')\n",
    "# mlt.ylabel('Energy Consumption in Kwh')\n",
    "# mlt.plot(tr, label='real')\n",
    "# mlt.legend()\n",
    "# mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4200,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = torch.from_numpy(real_test).float().to(device)\n",
    "missing_test = torch.from_numpy(missing_test).float().to(device)\n",
    "mask_test = torch.from_numpy(mask_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4201,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameters_seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4202,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_seq2seq, imputed_dataset, loss, mask_test_result = wrapper_test.test_model(model, real_test, missing_test, mask_test, loss_function_seq2seq, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4203,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_temp = ((1 - mask_test_result) * real_dataset_test_seq2seq) + (mask_test_result * imputed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4204,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_final_seq2seq = scaler_train_real.inverse_transform(imputed_dataset_temp.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4205,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_seq2seq_temp = scaler_train_real.inverse_transform(real_dataset_test_seq2seq.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4206,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_seq2seq_temp = pd.DataFrame(real_dataset_test_seq2seq_temp, columns=columns_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4207,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset + '_9-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4208,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_imputed_data(real_dataset_test_seq2seq, imputed_dataset_temp, \"../Data/Imputed/30_percent/Seq2Seq/\" + dataset_name + \".csv\", columns_extended, scaler_train_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4209,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_seq2seq = pd.DataFrame(real_dataset_test_seq2seq.detach().cpu().numpy(), columns=columns_extended)\n",
    "real_dataset_test_seq2seq = scaler_train_real.inverse_transform(real_dataset_test_seq2seq)\n",
    "real_dataset_test_seq2seq = torch.tensor(real_dataset_test_seq2seq)\n",
    "#real_dataset_test_seq2seq = pd.DataFrame(real_dataset_test_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4210,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_seq2seq = pd.DataFrame(imputed_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "imputed_dataset_seq2seq = scaler_train_real.inverse_transform(imputed_dataset_seq2seq)\n",
    "imputed_dataset_seq2seq = torch.tensor(imputed_dataset_seq2seq)\n",
    "#imputed_dataset = pd.DataFrame(imputed_dataset.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4211,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_test_seq2seq.detach().cpu().numpy(), imputed_dataset_seq2seq.detach().cpu().numpy(), 00, 3000, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4214,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_dataset_test_seq2seq[indices, 1], imputed_dataset_seq2seq[indices, 1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_imputation(real_dataset_test_seq2seq.numpy(), imputed_dataset.numpy(), mask_test_result.detach().cpu().numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_statistic, p_value = ks_2samp(real_dataset_test_seq2seq[:, 1], imputed_dataset_seq2seq[:, 1])\n",
    "\n",
    "# Print the results\n",
    "print(\"KS Statistic:\", ks_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv Gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0  # Mean of the distribution\n",
    "std_dev = 1  # Standard deviation of the distribution\n",
    "\n",
    "# Generate random data from a normal distribution\n",
    "random_data = np.random.normal(loc=mean, scale=std_dev, size=(real_train.size()))\n",
    "#random_data = np.clip(random_data, 0, 1)\n",
    "random_data = torch.tensor(random_data,dtype=torch.float32, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "generator = ConvGenerator(input_size, hidden_size, input_size).to(device)\n",
    "discriminator = ConvDiscriminator(input_size, hidden_size).to(device)\n",
    "optimizer_discriminator = torch.optim.RMSprop(discriminator.parameters(), lr = learning_rate)\n",
    "optimizer_generator = torch.optim.RMSprop(generator.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset, gen_dataset, errors_generator, errors_discriminator, mask_results = train_ConvGan(generator, discriminator, optimizer_discriminator, optimizer_generator, loss_function, real_train, missing_train, mask_train, step_per_epoch, random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imputation_results(real_dataset, gen_dataset, mask_results,100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset, gen_dataset, 300, 600, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = real_dataset[:, 7, 0]\n",
    "te = gen_dataset[:, 7, 0]\n",
    "ks_statistic, p_value = ks_2samp(tr.detach().cpu().numpy(), te.detach().cpu().numpy())\n",
    "\n",
    "# Print the results\n",
    "print(\"KS Statistic:\", ks_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_discriminator, label='d_loss')\n",
    "mlt.plot(errors_generator, label='g_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = mean_squared_error(tr.detach().cpu().numpy(), te.detach().cpu().numpy(), squared=False)\n",
    "print(f'RMSE:{RMSE}')\n",
    "\n",
    "mae = mean_absolute_error(tr.detach().cpu().numpy(), te.detach().cpu().numpy())\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(tr.detach().cpu().numpy(), te.detach().cpu().numpy())\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise_test = torch.tensor(np.random.randn(real_test.shape[0], lag_size, input_size), dtype=torch.float32, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = torch.from_numpy(real_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_test_conv, real_label_test_conv = gen_real_batch(real_test.shape[0], 0, real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = generator(real_data_test_conv, random_noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_test = real_data_test_conv[:, -1, 0]\n",
    "te_test = test_res[:, -1, 0]\n",
    "ks_statistic_test, p_value_test = ks_2samp(tr_test.detach().cpu().numpy(), te_test.detach().cpu().numpy())\n",
    "\n",
    "# Print the results\n",
    "print(\"KS Statistic:\", ks_statistic_test)\n",
    "print(\"P-value:\", p_value_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_test_conv, test_res, 300, 600, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = mean_squared_error(tr_test.detach().cpu().numpy(), te_test.detach().cpu().numpy(), squared=False)\n",
    "print(f'RMSE:{RMSE}')\n",
    "\n",
    "mae = mean_absolute_error(tr_test.detach().cpu().numpy(), te_test.detach().cpu().numpy())\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(tr_test.detach().cpu().numpy(), te_test.detach().cpu().numpy())\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2490,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelTrain(parameter_model)\n",
    "helper = ModelHelper(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2491,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(parameter_model).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameter_model.learning_rate)\n",
    "loss_function_autoencoder = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset, gen_dataset, errors_generator, mask_data = wrapper.train_Vae(model, optimizer, loss_function_autoencoder, real_train, missing_train, mask_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_generator, label='d_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset.detach().cpu().numpy(), gen_dataset.detach().cpu().numpy(), 2500, 3000, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2495,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_train_vae = pd.DataFrame(real_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "real_dataset_train_vae = scaler_train_real.inverse_transform(real_dataset_train_vae)\n",
    "real_dataset_train_vae = torch.tensor(real_dataset_train_vae)\n",
    "#real_dataset_train_seq2seq = pd.DataFrame(real_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)\n",
    "\n",
    "gen_dataset_train_vae = pd.DataFrame(gen_dataset.detach().cpu().numpy(), columns=columns_extended)\n",
    "gen_dataset_train_vae = scaler_train_real.inverse_transform(gen_dataset_train_vae)\n",
    "gen_dataset_train_vae = torch.tensor(gen_dataset_train_vae)\n",
    "#gen_dataset_train_seq2seq = pd.DataFrame(gen_dataset_train_seq2seq.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ..............................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2496,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = real_test[: -(real_test.shape[0] % parameter_model.batch_size)]\n",
    "missing_test = missing_test[: -(missing_test.shape[0] % parameter_model.batch_size)]\n",
    "mask_test = mask_test[: -(mask_test.shape[0] % parameter_model.batch_size)]\n",
    "\n",
    "step_per_epoch = len(missing_test) // parameter_model.batch_size\n",
    "\n",
    "real_test = torch.from_numpy(real_test).float().to(device)\n",
    "missing_test = torch.from_numpy(missing_test).float().to(device)\n",
    "mask_test = torch.from_numpy(mask_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2497,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameters_seq2seq)\n",
    "\n",
    "real_dataset_test_vae, imputed_dataset_vae, loss, mask_test_result = wrapper_test.test_Vae(model, real_test, missing_test, mask_test, loss_function_autoencoder, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2498,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_temp = ((1 - mask_test_result) * real_dataset_test_vae) + (mask_test_result * imputed_dataset_vae)\n",
    "\n",
    "imputed_dataset_final_vae = scaler_train_real.inverse_transform(imputed_dataset_temp.detach().cpu().numpy())\n",
    "\n",
    "real_dataset_test_vae_temp = scaler_train_real.inverse_transform(real_dataset_test_vae.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2499,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset + '_9-19'\n",
    "\n",
    "save_imputed_data(real_dataset_test_vae, imputed_dataset_temp, \"../Data/Imputed/30_percent/vae/\" + dataset_name + \".csv\", columns_extended, scaler_train_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2500,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_vae = pd.DataFrame(real_dataset_test_vae.detach().cpu().numpy(), columns=columns_extended)\n",
    "real_dataset_test_vae = scaler_train_real.inverse_transform(real_dataset_test_vae)\n",
    "real_dataset_test_vae = torch.tensor(real_dataset_test_vae)\n",
    "#real_dataset_test_seq2seq = pd.DataFrame(real_dataset_test_seq2seq.detach().cpu().numpy(), columns=columns)\n",
    "\n",
    "imputed_dataset_vae = pd.DataFrame(imputed_dataset_vae.detach().cpu().numpy(), columns=columns_extended)\n",
    "imputed_dataset_vae = scaler_train_real.inverse_transform(imputed_dataset_vae)\n",
    "imputed_dataset_vae = torch.tensor(imputed_dataset_vae)\n",
    "#imputed_dataset = pd.DataFrame(imputed_dataset.detach().cpu().numpy(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')\n",
    "\n",
    "plot_full_dataset(real_dataset_test_vae.detach().cpu().numpy(), imputed_dataset_vae.detach().cpu().numpy(), 00, 3000, 'Results/test_9-19.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(mask_test_result[:, 1] == 1).view(-1).to('cpu')\n",
    "\n",
    "validation_matrix_forecasting(real_dataset_test_vae[indices, 1], imputed_dataset_vae[indices, 1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4564,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = 0.50\n",
    "\n",
    "with open(\"config/config_data.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_acn = data.acn\n",
    "    parameters_boulder = data.boulder\n",
    "    parameters_paloalto = data.paloalto\n",
    "    parameters_sap = data.sap\n",
    "    parameters_perth = data.perth\n",
    "    parameters_dundee = data.dundee\n",
    "    parameters_caltech = data.caltech\n",
    "    parameters_jpl = data.jpl\n",
    "    parameters_office = data.office\n",
    "\n",
    "parameter_data = parameters_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4565,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"office2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4566,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Processed/\" + dataset_name + \"_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "# df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df = df.copy().loc[df['Start'] <= \"2020-12-31 23:00:00\"].reset_index(drop=True)\n",
    "\n",
    "df_test = df.copy().loc[(df['Start'] >= parameter_data.test.start) & (df['Start'] <= parameter_data.test.end)].reset_index(drop=True)\n",
    "\n",
    "# df_test['Start'] = pd.to_datetime(df_test['Start'])\n",
    "# df_test.set_index('Start', inplace=True)\n",
    "# result = seasonal_decompose(df_test['Energy'], model='additive', extrapolate_trend='freq')\n",
    "# df_test['Seasonal'] = result.seasonal\n",
    "# df_test['Trend'] = result.trend\n",
    "# df_test['Residual'] = result.resid\n",
    "# df_test.reset_index(inplace=True)\n",
    "\n",
    "df_test.drop(columns=['Start'], inplace=True)\n",
    "\n",
    "np.random.seed(0)\n",
    "ratio = round(missing_ratio * len(df_test))\n",
    "random_row_indices_test = np.random.choice(df_test.index, size=ratio, replace=False)\n",
    "\n",
    "missing_data = random_index_noise(df_test.copy(), random_row_indices_test)\n",
    "\n",
    "mask = np.isnan(missing_data)\n",
    "mask = mask.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model = MeanImputation()\n",
    "start = time.time()\n",
    "imputed_data_mean = model(missing_data, 'Energy')\n",
    "end = time.time()\n",
    "print(\"Time taken for mean imputation in minutes:\", (end-start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4568,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_mean = torch.tensor(imputed_data_mean.values)\n",
    "df_test = torch.tensor(df_test.values)\n",
    "mask = torch.tensor(mask.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4569,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_mean = ((1 - mask) * df_test) + (mask * imputed_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4570,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_knn = torch.nonzero(mask[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(df_test.detach().cpu().numpy(), imputed_data_mean.detach().cpu().numpy(), 000, 500, 'Results/test3.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4572,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(df_test[indices_knn, 1], imputed_data_mean[indices_knn, 1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3576,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = pd.DataFrame(imputed_data_mean, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3577,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data['Start'] = imputed_data.apply(lambda row: datetime(int(round(row['Year'])), int(round(row['Month'])), int(round(row['Day of month'])), int(round(row['Hour']))), axis=1)    \n",
    "# imputed_data['Sum'] = imputed_data.groupby(pd.to_datetime(imputed_data['Start']).dt.date)['Energy'].cumsum()\n",
    "imputed_data.drop(columns=['Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3578,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data.to_csv(\"../Data/Imputed/50_percent/Mean/\" + dataset_name + \"9_19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3371,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3372,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/config_data.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_acn = data.acn\n",
    "    parameters_boulder = data.boulder\n",
    "    parameters_paloalto = data.paloalto\n",
    "    parameters_sap = data.sap\n",
    "    parameters_perth = data.perth\n",
    "    parameters_dundee = data.dundee\n",
    "    parameters_caltech = data.caltech\n",
    "    parameters_jpl = data.jpl\n",
    "    parameters_office = data.office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3373,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_data = parameters_paloalto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3374,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name  = 'palo_alto2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Processed/\" + dataset_name + \"_data_with_zero.csv\")\n",
    "df['Hour'] = pd.to_datetime(df['Start']).dt.hour\n",
    "# df['Sum'] = df.groupby(pd.to_datetime(df['Start']).dt.date)['Energy'].cumsum()\n",
    "df = df.copy().loc[df['Start'] <= \"2020-12-31 23:00:00\"].reset_index(drop=True)\n",
    "\n",
    "df_test = df.copy().loc[(df['Start'] >= parameter_data.test.start) & (df['Start'] <= parameter_data.test.end)].reset_index(drop=True)\n",
    "\n",
    "# df_test['Start'] = pd.to_datetime(df_test['Start'])\n",
    "# df_test.set_index('Start', inplace=True)\n",
    "# result = seasonal_decompose(df_test['Energy'], model='additive', extrapolate_trend='freq')\n",
    "# df_test['Seasonal'] = result.seasonal\n",
    "# df_test['Trend'] = result.trend\n",
    "# df_test['Residual'] = result.resid\n",
    "# df_test.reset_index(inplace=True)\n",
    "\n",
    "df_test.drop(columns=['Start'], inplace=True)\n",
    "\n",
    "np.random.seed(0)\n",
    "ratio = round(missing_ratio * len(df_test))\n",
    "random_row_indices_test = np.random.choice(df_test.index, size=ratio, replace=False)\n",
    "\n",
    "missing_data = random_index_noise(df_test.copy(), random_row_indices_test)\n",
    "\n",
    "mask = np.isnan(missing_data)\n",
    "mask = mask.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3376,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_neighbour = get_optimum_k(df, missing_data)\n",
    "k_neighbour = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3379,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KnnImputer()\n",
    "imputed_data = model(missing_data, k_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3380,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = torch.tensor(imputed_data)\n",
    "df_test = torch.tensor(df_test.values)\n",
    "mask = torch.tensor(mask.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3381,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_knn = torch.nonzero(mask[:, 1] == 1).view(-1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_knn = set_null_at_indices(imputed_data['Energy'].values.tolist(), indices_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(df_test.detach().cpu().numpy(), imputed_data.detach().cpu().numpy(), 000, 1000, 'Results/test3.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(df_test[indices_knn, 1], imputed_data[indices_knn, 1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_imputation(df_test.detach().cpu().numpy(), imputed_data.detach().cpu().numpy(), mask.detach().cpu().numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3386,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = pd.DataFrame(imputed_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3387,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data['Start'] = imputed_data.apply(lambda row: datetime(int(round(row['Year'])), int(round(row['Month'])), int(round(row['Day of month'])), int(round(row['Hour']))), axis=1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_data['Sum'] = imputed_data.groupby(pd.to_datetime(imputed_data['Start']).dt.date)['Energy'].cumsum()\n",
    "imputed_data.drop(columns=['Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3389,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data.to_csv(\"../Data/Imputed/50_percent/Knn/\" + dataset_name + \"_9_19.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset = torch.tensor(imputed_dataset)\n",
    "real_dataset_test_seq2seq = torch.tensor(real_dataset_test_seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4502,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'caltech2'\n",
    "imputation = '50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4503,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=['Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4504,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_dataset_final_seq2seq = pd.read_csv(\"../Data/Imputed/\" + imputation + \"_percent/Seq2Seq/\" + dataset + \"_9-19.csv\")\n",
    "imputed_data_mean = pd.read_csv(\"../Data/Imputed/\" + imputation + \"_percent/Mean/\" + dataset + \"9_19.csv\")\n",
    "imputed_data_knn = pd.read_csv(\"../Data/Imputed/\" + imputation + \"_percent/Knn/\" + dataset + \"_9_19.csv\")\n",
    "imputed_dataset_final_gan = pd.read_csv(\"../Data/Imputed/\" + imputation + \"_percent/Gan/\" + dataset + \"_9-19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predicted_dataset(torch.tensor(df_test.values), torch.tensor(imputed_dataset_final_seq2seq.values), torch.tensor(imputed_data_knn.values), torch.tensor(imputed_data_mean.values), torch.tensor(imputed_dataset_final_gan.values), imputed_dataset_final_vae, 720, 960, 'Results/test_caltech_50_9_19.png', 1, 'Caltech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
