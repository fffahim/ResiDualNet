{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as mlt\n",
    "import seaborn as sp\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from types import SimpleNamespace\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Pre_process/Data_preprocess.ipynb\n",
    "%run Model/Mogrifier_LSTM.ipynb\n",
    "%run Model/Bi_LSTM.ipynb\n",
    "%run Model/LSTM.ipynb\n",
    "%run Model/SciNet.ipynb\n",
    "%run train.ipynb\n",
    "%run ../visualize.ipynb\n",
    "%run test.ipynb\n",
    "%run ../validation.ipynb\n",
    "%run wrapper.ipynb\n",
    "%run helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/config_model.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    parameters_bilstm = data.bilstm\n",
    "    parameters_mogrifierlstm = data.mogrifierlstm\n",
    "    parameters_scinet = data.scinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_model = parameters_scinet\n",
    "parameter_model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ModelTrain(parameter_model)\n",
    "helper = ModelHelper(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum']\n",
    "#columns = ['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum', 'Seasonal', 'Trend', 'Residual']\n",
    "# columns = ['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/Imputed/40_percent/Seq2Seq/caltech_last.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Hour'] = round(data['Hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Dataset Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../Data/Processed/palo_alto_data_with_zero.csv\")\n",
    "data2 = pd.read_csv(\"../Data/Processed/caltech_data_with_zero.csv\")\n",
    "data3 = pd.read_csv(\"../Data/Processed/jpl_data_with_zero.csv\")\n",
    "data4 = pd.read_csv(\"../Data/Processed/office_data_with_zero.csv\")\n",
    "\n",
    "data1_train = data1.loc[(data1['Start'] >= '2017-01-01 00:00:00') & (data1['Start'] <= '2019-09-30 23:00:00')].reset_index(drop=True)\n",
    "data2_train = data2.loc[(data2['Start'] >= '2017-01-01 00:00:00') & (data2['Start'] <= '2019-09-30 23:00:00')].reset_index(drop=True)\n",
    "data3_train = data3.loc[(data3['Start'] >= '2017-01-01 00:00:00') & (data3['Start'] <= '2019-09-30 23:00:00')].reset_index(drop=True)\n",
    "data4_train = data4.loc[(data4['Start'] >= '2017-01-01 00:00:00') & (data4['Start'] <= '2019-09-30 23:00:00')].reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([data1_train, data2_train, data3_train, data4_train], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_real_train = df.groupby('Start').agg({\n",
    "            'Day of week': 'first',\n",
    "            'Energy': 'mean',\n",
    "            'Week Day': 'first',\n",
    "            'Year': 'first',\n",
    "            'Month': 'first',\n",
    "            'Day of month': 'first'\n",
    "        }).reset_index()\n",
    "\n",
    "df_real_train['Hour'] = pd.to_datetime(df_real_train['Start']).dt.hour\n",
    "df_real_train['Sum'] = df_real_train.groupby(pd.to_datetime(df_real_train['Start']).dt.date)['Energy'].cumsum()\n",
    "\n",
    "# df_real_train['Start'] = pd.to_datetime(df_real_train['Start'])\n",
    "# df_real_train.set_index('Start', inplace=True)\n",
    "# result = seasonal_decompose(df_real_train['Energy'], model='additive', extrapolate_trend='freq')\n",
    "# df_real_train['Seasonal'] = result.seasonal\n",
    "# df_real_train['Trend'] = result.trend\n",
    "# df_real_train['Residual'] = result.resid\n",
    "# df_real_train.reset_index(inplace=True)\n",
    "\n",
    "df_real_train.drop(columns=['Start'], inplace=True)\n",
    "#df_real_train.drop(columns=['Start', 'Year', 'Day of week', 'Week Day', 'Month', 'Day of month'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_real_train = scaler.fit_transform(df_real_train)\n",
    "df_real_train = pd.DataFrame(df_real_train, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, ground_truth_train = get_train_test_dataset_forecasting(df_real_train, parameter_model.lag_size, parameter_model.future_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_test = data1.loc[(data1['Start'] >= '2019-10-01 00:00:00') & (data1['Start'] <= '2020-02-29 23:00:00')].reset_index(drop=True)\n",
    "data2_test = data2.loc[(data2['Start'] >= '2019-10-01 00:00:00') & (data2['Start'] <= '2020-02-29 23:00:00')].reset_index(drop=True)\n",
    "data3_test = data3.loc[(data3['Start'] >= '2019-10-01 00:00:00') & (data3['Start'] <= '2020-02-29 23:00:00')].reset_index(drop=True)\n",
    "data4_test = data4.loc[(data4['Start'] >= '2019-10-01 00:00:00') & (data4['Start'] <= '2020-02-29 23:00:00')].reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([data1_test, data2_test, data3_test, data4_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_real_test = df.groupby('Start').agg({\n",
    "            'Day of week': 'first',\n",
    "            'Energy': 'mean',\n",
    "            'Week Day': 'first',\n",
    "            'Year': 'first',\n",
    "            'Month': 'first',\n",
    "            'Day of month': 'first'\n",
    "        }).reset_index()\n",
    "\n",
    "df_real_test['Hour'] = pd.to_datetime(df_real_test['Start']).dt.hour\n",
    "df_real_test['Sum'] = df_real_test.groupby(pd.to_datetime(df_real_test['Start']).dt.date)['Energy'].cumsum()\n",
    "\n",
    "# df_real_test['Start'] = pd.to_datetime(df_real_test['Start'])\n",
    "# df_real_test.set_index('Start', inplace=True)\n",
    "# result = seasonal_decompose(df_real_test['Energy'], model='additive', extrapolate_trend='freq')\n",
    "# df_real_test['Seasonal'] = result.seasonal\n",
    "# df_real_test['Trend'] = result.trend\n",
    "# df_real_test['Residual'] = result.resid\n",
    "# df_real_test.reset_index(inplace=True)\n",
    "\n",
    "df_real_test.drop(columns=['Start'], inplace=True)\n",
    "#df_real_test.drop(columns=['Start', 'Year', 'Day of week', 'Week Day', 'Month', 'Day of month'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_test = MinMaxScaler(feature_range=(0,1))\n",
    "df_real_test = scaler_test.fit_transform(df_real_test)\n",
    "df_real_test = pd.DataFrame(df_real_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, ground_truth_test = get_train_test_dataset_forecasting(df_real_test, parameter_model.lag_size, parameter_model.future_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_train) // batch_size\n",
    "\n",
    "# Converting to tensor\n",
    "data_train = torch.from_numpy(data_train).float().to(device)\n",
    "ground_truth_train = torch.from_numpy(ground_truth_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"knn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../Data/Imputed/50_percent/\" + model_type + \"/palo_alto_final.csv\")\n",
    "data2 = pd.read_csv(\"../Data/Imputed/50_percent/\" + model_type + \"/caltech_final.csv\")\n",
    "data3 = pd.read_csv(\"../Data/Imputed/50_percent/\" + model_type + \"/jpl_final.csv\")\n",
    "data4 = pd.read_csv(\"../Data/Imputed/50_percent/\" + model_type + \"/office_final.csv\")\n",
    "\n",
    "df = pd.concat([data1, data2, data3, data4], axis=0).reset_index(drop=True)\n",
    "df['Hour'] = round(df['Hour'])\n",
    "df = df.rename(columns={'Day of month': 'Day_of_month'}) \n",
    "\n",
    "df['Start'] = pd.to_datetime(dict(year=round(df.Year), month=round(df.Month), day=round(df.Day_of_month), hour=round(df.Hour)))\n",
    "\n",
    "df = df.loc[df['Start'] <= '2020-12-31 23:00:00'].reset_index(drop=True)\n",
    "\n",
    "df = df.rename(columns={'Day_of_month': 'Day of month'}) \n",
    "\n",
    "df_real_test = df.groupby('Start').agg({\n",
    "            'Day of week': 'first',\n",
    "            'Energy': 'mean',\n",
    "            'Week Day': 'first',\n",
    "            'Year': 'first',\n",
    "            'Month': 'first',\n",
    "            'Day of month': 'first'\n",
    "        }).reset_index()\n",
    "\n",
    "df_real_test['Hour'] = pd.to_datetime(df_real_test['Start']).dt.hour\n",
    "df_real_test['Sum'] = df_real_test.groupby(pd.to_datetime(df_real_test['Start']).dt.date)['Energy'].cumsum()\n",
    "df_real_test.drop(columns=['Start'], inplace=True)\n",
    "\n",
    "scaler_test = MinMaxScaler(feature_range=(0,1))\n",
    "df_real_test = scaler_test.fit_transform(df_real_test)\n",
    "df_real_test = pd.DataFrame(df_real_test, columns=columns)\n",
    "\n",
    "data_test, ground_truth_test = get_train_test_dataset_forecasting(df_real_test, parameter_model.lag_size, parameter_model.future_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mogrifier LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainning------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mogrifier_LSTM(parameter_model).to(device)\n",
    "#model = Seq2SeqAttention(input_size, hidden_size, input_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameter_model.learning_rate, weight_decay = 0.005)\n",
    "loss_function_mogrifier = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_mogrifier, gen_dataset_mogrifier, errors_generator_mogrifier = wrapper.train_mogrifier_lstm(model, optimizer, loss_function_mogrifier, data_train, ground_truth_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset_mogrifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_mogrifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_generator_mogrifier, label='d_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset_mogrifier.view(batch_size, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_mogrifier[:,0, :].detach().cpu().numpy(), gen_dataset_mogrifier[:, 0, :].detach().cpu().numpy(), 600, 52000, 'Results/test1.png', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_test) // parameter_model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_mogrifier, predicted_dataset_mogrifier, loss = wrapper_test.test_model(model, data_test, ground_truth_test, loss_function_mogrifier, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_test_mogrifier[:, 0, :].detach().cpu().numpy(), predicted_dataset_mogrifier[:, 0, :].detach().cpu().numpy(), 500, 10000, 'Results/test3.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test_mogrifier = pd.DataFrame(real_dataset_test_mogrifier[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "real_dataset_test_mogrifier = scaler_test.inverse_transform(real_dataset_test_mogrifier)\n",
    "real_dataset_test_mogrifier = torch.tensor(real_dataset_test_mogrifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset_mogrifier = pd.DataFrame(predicted_dataset_mogrifier[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "predicted_dataset_mogrifier = scaler_test.inverse_transform(predicted_dataset_mogrifier)\n",
    "predicted_dataset_mogrifier = torch.tensor(predicted_dataset_mogrifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_dataset_test_mogrifier[:, 1].detach().cpu().numpy(), predicted_dataset_mogrifier[:, 1].detach().cpu().numpy(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bi_LSTM(parameter_model).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameter_model.learning_rate, weight_decay = 0.005)\n",
    "loss_function_bilstm = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_bilstm, gen_dataset_bilstm, errors_generator_bilstm = wrapper.train_bi_lstm(model, optimizer, loss_function_bilstm, data_train, ground_truth_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_generator_bilstm, label='d_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_bilstm[:, 0, :].detach().cpu().numpy(), gen_dataset_bilstm[:, 0, :].detach().cpu().numpy(), 00, 500, 'Results/test1.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % parameter_model.batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % parameter_model.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_test) // parameter_model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_bilstm, predicted_data_bilstm, loss_bilstm = wrapper_test.test_model(model, data_test, ground_truth_test, loss_function_bilstm, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_bilstm[:, 0, :].detach().cpu().numpy(), predicted_data_bilstm[:, 0, :].detach().cpu().numpy(), 000, 20000, 'Results/test3.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss_bilstm[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_bilstm = pd.DataFrame(real_data_bilstm[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "real_data_bilstm = scaler_test.inverse_transform(real_data_bilstm)\n",
    "real_data_bilstm = torch.tensor(real_data_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data_bilstm = pd.DataFrame(predicted_data_bilstm[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "predicted_data_bilstm = scaler_test.inverse_transform(predicted_data_bilstm)\n",
    "predicted_data_bilstm = torch.tensor(predicted_data_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_data_bilstm[:, 1].detach().cpu().numpy(), predicted_data_bilstm[:, 1].detach().cpu().numpy(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 16\n",
    "model = vanilla_LSTM(input_size, hidden_size, future_step).to(device)\n",
    "#model = Seq2SeqAttention(input_size, hidden_size, input_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.005)\n",
    "loss_function_seq2seq = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_vanilla_lstm, gen_dataset_vanilla_lstm, errors_generator_vanilla_lstm = train_vanilla_lstm(model, optimizer, loss_function_seq2seq, data_train, ground_truth_train, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "mlt.plot(errors_generator_vanilla_lstm, label='d_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_vanilla_lstm[:].detach().cpu().numpy(), gen_dataset_vanilla_lstm[:].detach().cpu().numpy(), 00, 50000, 'Results/test1.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Imputed/Mean_imputation/perth.csv\")\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(df, columns=['Day of week', 'Energy', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data_test, _, ground_truth_test = get_train_test_dataset_forecasting(df, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_test) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_lstm, predicted_data_lstm, loss_lstm = test_model(model, data_test, ground_truth_test, loss_function_seq2seq, step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_lstm.detach().cpu().numpy(), predicted_data_lstm.detach().cpu().numpy(), 000, 5000, 'Results/test3.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss_lstm[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_data_lstm.view(-1).detach().cpu().numpy(), predicted_data_lstm.view(-1).detach().cpu().numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predicted_dataset(real_data_lstm.detach().cpu().numpy(), predicted_dataset_mogrifier.detach().cpu().numpy(), predicted_data_bilstm.detach().cpu().numpy(), predicted_data_lstm.detach().cpu().numpy(), 000, 50, 'Results/compare.png', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCINet(output_len = parameter_model.future_step, input_len= parameter_model.lag_size, input_dim = parameter_model.input_size, hid_size = hidden_size, num_stacks = parameter_model.stacks,\n",
    "                num_levels = parameter_model.levels, concat_len = 0, groups = 1, kernel = 4, dropout = 0.2,\n",
    "                 single_step_output_One = 0, positionalE =  False, modified = True).to(device)\n",
    "#model = Seq2SeqAttention(input_size, hidden_size, input_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = parameter_model.learning_rate, weight_decay = 0.005)\n",
    "loss_function_scinet = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_scinet, gen_dataset_scinet, errors_generator_scinet = wrapper.train_scinet(model, loss_function_scinet, optimizer, data_train, ground_truth_train, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_dataset_scinet[:, 0, :].detach().cpu().numpy(), gen_dataset_scinet[:, 0, :].detach().cpu().numpy(), 300, 8000, 'Results/test1.png', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % parameter_model.batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % parameter_model.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch = len(data_test) // parameter_model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_test = ModelTest(parameter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_scinet, predicted_data_scinet, loss_scinet = wrapper_test.test_model(model, data_test, ground_truth_test, loss_function_scinet, step_per_epoch, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(real_data_scinet[:, 0, :].detach().cpu().numpy(), predicted_data_scinet[:, 0, :].detach().cpu().numpy(), 000, 50000, 'Results/test3.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt.suptitle('Loss')\n",
    "#mlt.plot(errors_generator, label='train_loss')\n",
    "mlt.plot(loss_scinet[:], label='test_loss')\n",
    "mlt.legend()\n",
    "#mlt.savefig('foo1.png')\n",
    "mlt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_scinet = pd.DataFrame(real_data_scinet[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "real_data_scinet = scaler_test.inverse_transform(real_data_scinet)\n",
    "real_data_scinet = torch.tensor(real_data_scinet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data_scinet = pd.DataFrame(predicted_data_scinet[:, 0, :].detach().cpu().numpy(), columns=columns)\n",
    "predicted_data_scinet = scaler_test.inverse_transform(predicted_data_scinet)\n",
    "predicted_data_scinet = torch.tensor(predicted_data_scinet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(real_data_scinet[:, 1].detach().cpu().numpy(), predicted_data_scinet[:, 1].detach().cpu().numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_folders = ['Seq2Seq', 'Mean_imputation', 'Knn']\n",
    "datasets = ['acn', 'boulder', 'dundee', 'palo_alto', 'perth', 'sap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_folders = ['Processed']\n",
    "datasets = ['acn_data_with_zero', 'boulder_data_with_zero', 'dundee_data_with_zero', 'palo_alto_data_with_zero', 'perth_data_with_zero', 'sap_data_with_zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in impute_folders:\n",
    "    print(i + \"---->\")\n",
    "    for j in datasets:\n",
    "        print(j + \":\")\n",
    "        df = pd.read_csv(\"../Data/Imputed/\" + i + \"/\" + j + \".csv\")\n",
    "        #df = df[: 8760]\n",
    "        # df.drop(columns=['Start', 'Year', 'Day of week', 'Week Day', 'Month', 'Day of month'], inplace=True)\n",
    "        df.drop(columns=['Day of week', 'Week Day', 'Year', 'Month', 'Day of month', 'Hour', 'Sum'], inplace=True)\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        df = scaler.fit_transform(df)\n",
    "        df = pd.DataFrame(df, columns=columns)\n",
    "\n",
    "        train_ratio = 0\n",
    "\n",
    "        _, data_test, _, ground_truth_test = get_train_test_dataset_forecasting(df, train_ratio)\n",
    "\n",
    "        # data_test = data_test[: -(data_test.shape[0] % batch_size)]\n",
    "        # ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % batch_size)]\n",
    "\n",
    "        data_test = torch.from_numpy(data_test).float().to(device)\n",
    "        ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if stacks == 1:\n",
    "                outputs = model(data_test)\n",
    "            elif stacks == 2:\n",
    "                outputs, _ = model(data_test)\n",
    "\n",
    "        ground_truth_test = pd.DataFrame(ground_truth_test[:, -1, :].detach().cpu().numpy(), columns=columns)\n",
    "        ground_truth_test = scaler.inverse_transform(ground_truth_test)\n",
    "        ground_truth_test = torch.tensor(ground_truth_test)\n",
    "\n",
    "        outputs = pd.DataFrame(outputs[:, -1, :].detach().cpu().numpy(), columns=columns)\n",
    "        outputs = scaler.inverse_transform(outputs)\n",
    "        outputs = torch.tensor(outputs)\n",
    "\n",
    "        validation_matrix_forecasting(ground_truth_test.detach().cpu().numpy(), outputs.detach().cpu().numpy(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Processed/acn_data_with_zero.csv\")\n",
    "df = df[: 8760]\n",
    "df.drop(columns=['Start', 'Year', 'Day of week', 'Week Day', 'Month', 'Day of month'], inplace=True)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, data_test, _, ground_truth_test = get_train_test_dataset_forecasting(df, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[: -(data_test.shape[0] % batch_size)]\n",
    "ground_truth_test = ground_truth_test[: -(ground_truth_test.shape[0] % batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.from_numpy(data_test).float().to(device)\n",
    "ground_truth_test = torch.from_numpy(ground_truth_test).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if stacks == 1:\n",
    "        outputs = model(data_test)\n",
    "    elif stacks == 2:\n",
    "        outputs, _ = model(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test = pd.DataFrame(ground_truth_test[:, -1, :].detach().cpu().numpy(), columns=['Energy'])\n",
    "ground_truth_test = scaler.inverse_transform(ground_truth_test)\n",
    "ground_truth_test = torch.tensor(ground_truth_test)\n",
    "\n",
    "outputs = pd.DataFrame(outputs[:, -1, :].detach().cpu().numpy(), columns=['Energy'])\n",
    "outputs = scaler.inverse_transform(outputs)\n",
    "outputs = torch.tensor(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix_forecasting(ground_truth_test.detach().cpu().numpy(), outputs.detach().cpu().numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_dataset(ground_truth_test.detach().cpu().numpy(), outputs.detach().cpu().numpy(), 1000, 1500, 'Results/test1.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    '1 Hour': {'MoG-LSTM': 0.55, 'BiLSTM': 0.57, 'LSTM': 0.57},\n",
    "    '4 Hour': {'MoG-LSTM': 0.29, 'BiLSTM': 0.23, 'LSTM': 0.27},\n",
    "    '8 Hour': {'MoG-LSTM': 0.25, 'BiLSTM': 0.12, 'LSTM': 0.14}\n",
    "}\n",
    "plot_r2_score(results, \"Results/compare_hourly.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices = np.random.choice(100, size=40, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
